{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"level2_2w_심화 2번 과제 - Pose Estimation.ipynb","provenance":[{"file_id":"1g_PdoWG5Wpydp28Laqx-2yWQ5xNQ3O-3","timestamp":1647222542383}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1UL2tS-EQZKN"},"source":["# 심화과제 2: Body Landmark Localization using Hourglass Network\n"]},{"cell_type":"markdown","metadata":{"id":"RzUKwSFFh36a"},"source":["이번 과제에서는 사람의 관절과 같은 자세 추정을 위한 모델을 구현해봅니다. Keypoint 또는 Landmark라고 부르는 주요 포인트를 찾는 문제로, 다른 과제에서 다룬 Classification, Segmentation 모델들과는 다른 형태의 CNN 구조를 요구합니다. \n","\n","입력과 출력의 공간 해상도가 비슷하게 유지되어야 할 때 많이 사용되는 UNet과 Hourglass networks라 불리는 방법들을 구현할 때 유의해야할 점과 Classification 문제를 Regression 문제로 치환하는 고급 테크닉에 대해서 공부하게 됩니다.\n","\n","Landmark localization은 대표적인 regression문제이나, CNN은 classification문제를 더 잘 다루는 경향성이 있습니다. 따라서 classification문제를 어떻게 regression문제로 치환할지 고민해봅시다.\n","\n","과제 목표: \n","- Hourglass 구조를 적층할 때, 공간 및 채널 차원 수 일치를 고민하여 모델을 설계할 수 있다.\n","- CNN이 잘하는 classification문제로 regression 문제를 푸는 방법에 대해서 익힌다.\n"]},{"cell_type":"code","metadata":{"id":"3JNiQ2H2nS-r","executionInfo":{"status":"ok","timestamp":1647237752143,"user_tz":-540,"elapsed":5473,"user":{"displayName":"멋쟁이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07756606377067959175"}}},"source":["# Seed\n","import torch\n","import numpy as np\n","import random\n","\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)\n","np.random.seed(0)\n","random.seed(0)\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F-nCnWRyQh2P"},"source":["### **4.1 Hourglass Module Implementation**\n","\n","아래 **Fig. 3.**에 표현되어 있는 **Hourglass module**을 구현하고자 합니다. 이미 선언되어 있는 layer들을 이용하여 figure 상의 layer 구성과 동일하게 tensor가 forward 될 수 있도록 ```def forward``` 부분을 완성해주세요.\n","\n","\n","- Fig. 4. Right에 표현된 supervision layer는 해당 과제에서는 고려하지 않습니다.\n","- The figures are from [the original hourglass paper](https://arxiv.org/abs/1603.06937) [Newell et al.].\n","\n","<img src='https://drive.google.com/uc?id=19-S7TwZ62joUR8W9031xjn3jMZyTevpw'  width=\"700\">\n","\n","<img src='https://drive.google.com/uc?id=1ols0VZ7TGZCMDM7sKzCJq3bByHsOU9up'  width=\"700\">"]},{"cell_type":"markdown","metadata":{"id":"pRXBDC0qkhkP"},"source":["아래의 코드는 Hourglass 모듈을 나타내는 클래스입니다. 위의 Figure를 참고하여 **TO DO** 과제를 채워주세요 :)\n","\n","- **TO DO** : ```class Hourglass```는 하나의 Hourglass 모듈을 의미하며 이전에 선언한 ```class ResidualBlock```을 기본 convolution block으로 사용합니다. Hourglass 내부에 사용되는 layer는 이미 ```def __init__```에 선언이 되어 있지만 `**``def forward``` 부분은 완성되지 않아 선언된 layer들을 구성에 맞게 연결**해주어야 합니다. Fig. 3.을 참고하여 Hourglass 모듈을 올바르게 구현해주세요 :)"]},{"cell_type":"code","metadata":{"id":"zehDRYDCkTsK","executionInfo":{"status":"ok","timestamp":1647237885487,"user_tz":-540,"elapsed":646,"user":{"displayName":"멋쟁이","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07756606377067959175"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ResidualBlock(nn.Module):\n","  def __init__(self, num_channels=256):\n","    super(ResidualBlock, self).__init__()\n","\n","    self.bn1 = nn.BatchNorm2d(num_channels)\n","    self.conv1 = nn.Conv2d(num_channels, num_channels//2, kernel_size=1, bias=True)\n","\n","    self.bn2 = nn.BatchNorm2d(num_channels//2)\n","    self.conv2 = nn.Conv2d(num_channels//2, num_channels//2, kernel_size=3, stride=1,\n","                              padding=1, bias=True)\n","\n","    self.bn3 = nn.BatchNorm2d(num_channels//2)\n","    self.conv3 = nn.Conv2d(num_channels//2, num_channels, kernel_size=1, bias=True)\n","\n","    self.relu = nn.ReLU(inplace=True)\n","\n","  def forward(self, x):\n","    residual = x\n","\n","    out = self.bn1(x)\n","    out = self.relu(out)\n","    out = self.conv1(out)\n","\n","    out = self.bn2(out)\n","    out = self.relu(out)\n","    out = self.conv2(out)\n","\n","    out = self.bn3(out)\n","    out = self.relu(out)\n","    out = self.conv3(out)\n","\n","    out += residual\n","\n","    return out"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"IiK_5kEYQsda"},"source":["class Hourglass(nn.Module):\n","  def __init__(self, block, num_channels=256):\n","    super(Hourglass, self).__init__()\n","\n","    self.downconv_1 = block(num_channels)\n","    self.pool_1 = nn.MaxPool2d(kernel_size=2)\n","    self.downconv_2 = block(num_channels)\n","    self.pool_2 = nn.MaxPool2d(kernel_size=2)\n","    self.downconv_3 = block(num_channels)\n","    self.pool_3 = nn.MaxPool2d(kernel_size=2)\n","    self.downconv_4 = block(num_channels)\n","    self.pool_4 = nn.MaxPool2d(kernel_size=2)\n","\n","    self.midconv_1 = block(num_channels)\n","    self.midconv_2 = block(num_channels)\n","    self.midconv_3 = block(num_channels)\n","    \n","    self.skipconv_1 = block(num_channels)\n","    self.skipconv_2 = block(num_channels)\n","    self.skipconv_3 = block(num_channels)\n","    self.skipconv_4 = block(num_channels)\n","\n","    self.upconv_1 = block(num_channels)\n","    self.upconv_2 = block(num_channels)\n","    self.upconv_3 = block(num_channels)\n","    self.upconv_4 = block(num_channels)\n","\n","  def forward(self, x):\n","    x1 = self.downconv_1(x)\n","    x  = self.pool_1(x1)\n","\n","    '''======================================================='''\n","    '''======================== TO DO ========================'''\n","    x2 = \n","    x  = \n","    x3 = \n","    x  = \n","    x4 = \n","    x  = \n","\n","    x = \n","    x = \n","    x = \n","\n","    x4 = \n","    x = F.upsample(x, scale_factor=2)\n","    x = x + \n","    x = \n","\n","    x3 = \n","    x = F.upsample(x, scale_factor=2)\n","    x = x + \n","    x = \n","\n","    x2 = \n","    x = F.upsample(x, scale_factor=2)\n","    x = x + \n","    x = \n","\n","    x1 = \n","    x = F.upsample(x, scale_factor=2)\n","    x = x + \n","    x = \n","    '''======================== TO DO ========================'''\n","    '''======================================================='''\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VZfXyBDfldbE"},"source":["----\n","[torchsummary](https://github.com/sksq96/pytorch-summary)는 PyTorch로 구현한 네트워크를 직관적으로 확인할 수 있는 라이브러리입니다.\n","\n","해당 라이브러리를 이용하여 각 feature map의 dimension과 각각의 layer가 몇개의 parameter 수를 가지고 있는지 확인해 봅시다!"]},{"cell_type":"code","metadata":{"id":"i1-T5hNpYhI1"},"source":["# Let's summary the implemented hourglass architecture using torchsummary library.\n","hg = Hourglass(ResidualBlock)\n","\n","from torchsummary import summary\n","summary(hg, input_size=(256,64,64), device='cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tOETu9-yd_CV"},"source":["----\n","### **4.2 Human Pose Estimation**\n","\n","[Stacked Hourglass Network](https://arxiv.org/abs/1603.06937)를 이용하여 human pose estimation task를 수행하여 봅시다!\n","\n","<img src='https://drive.google.com/uc?id=1gJPaBX8uVWY9FnNRf2H3rmP1xYsd73eR'  width=\"900\">"]},{"cell_type":"markdown","metadata":{"id":"Gp1OcSEZwhcn"},"source":["##### **>>> 4.2.1 Stacked Hourglass Network**\n","아래 코드는 stacked hourglass network의 전체 코드입니다. ([원본 github 링크](https://github.com/bearpaw/pytorch-pose))\n","\n","- 3.1에서 Hourglass 모듈을 구현할 때 일일이 layer를 쌓는 것 대신에 for loop와 [nn.ModuleList](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html)를 이용하여 더욱 직관적이고 명료한 코드 작성이 가능하다는 것도 한번 확인해보세요 :)"]},{"cell_type":"code","metadata":{"id":"ooCFffn9xavs"},"source":["'''\n","Hourglass network inserted in the pre-activated Resnet\n","Use lr=0.01 for current version\n","(c) YANG, Wei\n","'''\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# from .preresnet import BasicBlock, Bottleneck\n","\n","\n","__all__ = ['HourglassNet', 'hg']\n","\n","class Bottleneck(nn.Module):\n","    expansion = 2\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","\n","        self.bn1 = nn.BatchNorm2d(inplanes)\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=True)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=True)\n","        self.bn3 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 2, kernel_size=1, bias=True)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.bn1(x)\n","        out = self.relu(out)\n","        out = self.conv1(out)\n","\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","\n","        out = self.bn3(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","\n","        return out\n","\n","\n","class Hourglass(nn.Module):\n","    def __init__(self, block, num_blocks, planes, depth):\n","        super(Hourglass, self).__init__()\n","        self.depth = depth\n","        self.block = block\n","        self.hg = self._make_hour_glass(block, num_blocks, planes, depth)\n","\n","    def _make_residual(self, block, num_blocks, planes):\n","        layers = []\n","        for i in range(0, num_blocks):\n","            layers.append(block(planes*block.expansion, planes))\n","        return nn.Sequential(*layers)\n","\n","    def _make_hour_glass(self, block, num_blocks, planes, depth):\n","        hg = []\n","        for i in range(depth):\n","            res = []\n","            for j in range(3):\n","                res.append(self._make_residual(block, num_blocks, planes))\n","            if i == 0:\n","                res.append(self._make_residual(block, num_blocks, planes))\n","            hg.append(nn.ModuleList(res))\n","        return nn.ModuleList(hg)\n","\n","    def _hour_glass_forward(self, n, x):\n","        up1 = self.hg[n-1][0](x)\n","        low1 = F.max_pool2d(x, 2, stride=2)\n","        low1 = self.hg[n-1][1](low1)\n","\n","        if n > 1:\n","            low2 = self._hour_glass_forward(n-1, low1)\n","        else:\n","            low2 = self.hg[n-1][3](low1)\n","        low3 = self.hg[n-1][2](low2)\n","        up2 = F.interpolate(low3, scale_factor=2)\n","        out = up1 + up2\n","        return out\n","\n","    def forward(self, x):\n","        return self._hour_glass_forward(self.depth, x)\n","\n","\n","class HourglassNet(nn.Module):\n","    '''Hourglass model from Newell et al ECCV 2016'''\n","    def __init__(self, block, num_stacks=2, num_blocks=4, num_classes=16):\n","        super(HourglassNet, self).__init__()\n","\n","        self.inplanes = 64\n","        self.num_feats = 128\n","        self.num_stacks = num_stacks\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n","                               bias=True)\n","        self.bn1 = nn.BatchNorm2d(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.layer1 = self._make_residual(block, self.inplanes, 1)\n","        self.layer2 = self._make_residual(block, self.inplanes, 1)\n","        self.layer3 = self._make_residual(block, self.num_feats, 1)\n","        self.maxpool = nn.MaxPool2d(2, stride=2)\n","\n","        # build hourglass modules\n","        ch = self.num_feats*block.expansion\n","        hg, res, fc, score, fc_, score_ = [], [], [], [], [], []\n","        for i in range(num_stacks):\n","            hg.append(Hourglass(block, num_blocks, self.num_feats, 4))\n","            res.append(self._make_residual(block, self.num_feats, num_blocks))\n","            fc.append(self._make_fc(ch, ch))\n","            score.append(nn.Conv2d(ch, num_classes, kernel_size=1, bias=True))\n","            if i < num_stacks-1:\n","                fc_.append(nn.Conv2d(ch, ch, kernel_size=1, bias=True))\n","                score_.append(nn.Conv2d(num_classes, ch, kernel_size=1, bias=True))\n","        self.hg = nn.ModuleList(hg)\n","        self.res = nn.ModuleList(res)\n","        self.fc = nn.ModuleList(fc)\n","        self.score = nn.ModuleList(score)\n","        self.fc_ = nn.ModuleList(fc_)\n","        self.score_ = nn.ModuleList(score_)\n","\n","    def _make_residual(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=True),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _make_fc(self, inplanes, outplanes):\n","        bn = nn.BatchNorm2d(inplanes)\n","        conv = nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=True)\n","        return nn.Sequential(\n","                conv,\n","                bn,\n","                self.relu,\n","            )\n","\n","    def forward(self, x):\n","        out = []\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layer1(x)\n","        x = self.maxpool(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","\n","        for i in range(self.num_stacks):\n","            y = self.hg[i](x)\n","            y = self.res[i](y)\n","            y = self.fc[i](y)\n","            score = self.score[i](y)\n","            out.append(score)\n","            if i < self.num_stacks-1:\n","                fc_ = self.fc_[i](y)\n","                score_ = self.score_[i](score)\n","                x = x + fc_ + score_\n","\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZw8Uolpbzn6"},"source":["# model = HourglassNet(Bottleneck, num_stacks=1, num_blocks=2, num_classes=22).cuda()\n","model = HourglassNet(Bottleneck, num_stacks=1, num_blocks=2, num_classes=22)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B6aQQIGZxljN"},"source":["----\n","##### **>>> 4.2.2 Custom Body Landmark Dataset**\n","해당 과제에서는 이미지 속 인물의 여러 신체 부위를 keypoint 형태로 예측하는 네트워크를 학습시키고자 합니다. (학습 시간 단축을 위해 일부 데이터만 사용)"]},{"cell_type":"markdown","metadata":{"id":"22ehOuP0seQg"},"source":["과제를 수행하기 앞서 메일로 별도로 전달해드린  **```APY191016001_Body_Landmarks_Dataset_Shared_Subset_20p.zip```** 압축 파일의 데이터를 준비해주세요!\n","\n","\n","<br></br>**주의!** 해당 과정은 **데이터 저작권 보호**를 위해 교육이 종료된 이후에 해당 데이터셋을 **파기**할 것을 원칙으로 합니다."]},{"cell_type":"code","metadata":{"id":"HFBV7FShE4q-"},"source":["# Mount the google drive to access the dataset.\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGgSgaaBQ80i"},"source":["# 저장하신 압축 파일의 경로에 맞게 아래의 압축 해제 명령어를 수정해주세요. (!tar -zxvf 압축파일_경로 -C 저장할_폴더)\n","\n","!unzip /content/gdrive/MyDrive/APY191016001_Body_Landmarks_Dataset_Shared_Subset_20p.zip -d /content/BodyLandmarkData"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ChDPHjqgFE_3"},"source":["# Hyper-paramter Settings\n","data_root = '/content/BodyLandmarkData/data'\n","log_dir   = '/content/BodyLandmarkData/log'\n","\n","epochs = 3\n","batch_size = 8\n","lr = 1e-3\n","input_size = 320"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5YzW4g_It3ix"},"source":["학습을 위해서는 제공받은 데이터셋의 landmark 정보를 parsing하여 heatmap 형태로 나타내어야 합니다.\n","\n","Gaussin heatmap 형태로 keypoint를 나타내기 위하여 7강 강의 자료의 24번째 슬라이드를 참고하여 **TO DO**를 채워주세요 "]},{"cell_type":"code","metadata":{"id":"x28F_kjzRyus"},"source":["# Dataset\n","import torch\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","\n","import os\n","import cv2\n","import json\n","import numpy as np\n","from glob import glob\n","\n","class BodyLandmarkDataset(Dataset):\n","  def __init__(self, data_root, is_Train=True, input_size=224, transform=None):\n","    super(BodyLandmarkDataset, self).__init__()\n","\n","    self.img_list = self._load_img_list(data_root, is_Train)\n","\n","    self.len = len(self.img_list)\n","    self.input_size = input_size\n","    self.hm_size = input_size//4\n","    self.transform = transform\n","    \n","    self.n_landmarks = 22\n","    self.sigma = 1.5\n","\n","  def __getitem__(self, index):\n","    img_path = self.img_list[index]\n","    anno_path = img_path.replace('.jpg', '.json')\n","    \n","    # Image Loading\n","    img = cv2.imread(img_path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = img/255.\n","    \n","    org_size = img.shape[:2]\n","\n","    if self.transform:\n","      img = self.transform(img)\n","\n","    # Ground Truth\n","    heatmap = self._get_heatmaps_from_json(anno_path, org_size)\n","\n","    return img, heatmap\n","\n","  def __len__(self):\n","    return self.len\n","  \n","  def _load_img_list(self, data_root, is_Train):\n","    # Change the name of directory which has inconsistent naming rule.\n","    full_img_list = glob(os.path.join(data_root, 'single', '*', '*color.jpg'))\n","    \n","    # ID < 400 for Training\n","    # 400 < ID for Validation\n","    if is_Train:\n","      return [path for path in full_img_list if (self._load_img_ID(path) < 400)]\n","    else:\n","      return [path for path in full_img_list if (400 < self._load_img_ID(path))]\n","\n","  def _load_img_ID(self, path):\n","    return int(path.split(os.sep)[-2].strip('id_1'))\n","\n","  def _get_heatmaps_from_json(self, anno_path, org_size):\n","    # Parse point annotation\n","    with open(anno_path, 'r') as json_file:\n","      pts = json.load(json_file)\n","    pts = np.array([(pt['pt_x'], pt['pt_y']) for pt in pts['DataList'][0]['coordinates']])\n","\n","    pts[:,0] = pts[:,0] / org_size[1] * self.hm_size\n","    pts[:,1] = pts[:,1] / org_size[0] * self.hm_size\n","\n","    heatmap = np.zeros((self.n_landmarks, self.hm_size, self.hm_size), dtype=np.float32)\n","    for i, pt in enumerate(pts):\n","      heatmap[i] = self._draw_labelmap(heatmap[i], org_size, pt, self.sigma)\n","    \n","    return heatmap\n","\n","  def _draw_labelmap(self, heatmap, org_size, pt, sigma):\n","    # Draw a 2D gaussian\n","    # Adopted from https://github.com/anewell/pose-hg-train/blob/master/src/pypose/draw.py\n","    H, W = heatmap.shape[:2]\n","\n","    # Check that any part of the gaussian is in-bounds\n","    ul = [int(pt[0] - 3 * sigma), int(pt[1] - 3 * sigma)]\n","    br = [int(pt[0] + 3 * sigma + 1), int(pt[1] + 3 * sigma + 1)]\n","    if (ul[0] >= heatmap.shape[1] or ul[1] >= heatmap.shape[0] or\n","            br[0] < 0 or br[1] < 0):\n","        # If not, just return the image as is\n","        return heatmap, 0\n","\n","    # Generate gaussian\n","    size = 6 * sigma + 1\n","    x = np.arange(0, size, 1, float)\n","    y = x[:, np.newaxis]\n","    x0 = y0 = size // 2\n","    # The gaussian is not normalized, we want the center value to equal 1\n","\n","    '''======================================================='''\n","    '''======================== TO DO ========================'''\n","    g = \n","    '''======================== TO DO ========================'''\n","    '''======================================================='''\n","\n","    # Usable gaussian range\n","    g_x = max(0, -ul[0]), min(br[0], heatmap.shape[1]) - ul[0]\n","    g_y = max(0, -ul[1]), min(br[1], heatmap.shape[0]) - ul[1]\n","    # Image range\n","    heatmap_x = max(0, ul[0]), min(br[0], heatmap.shape[1])\n","    heatmap_y = max(0, ul[1]), min(br[1], heatmap.shape[0])\n","\n","    heatmap[heatmap_y[0]:heatmap_y[1], heatmap_x[0]:heatmap_x[1]] = g[g_y[0]:g_y[1], g_x[0]:g_x[1]]\n","    return heatmap\n","    \n","    return anno_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHBs5pAOWKoP"},"source":["# Dataset and Data Loader\n","MEAN = [0.485, 0.456, 0.406]\n","STD  = [0.229, 0.224, 0.225]\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((input_size, input_size)),\n","    transforms.Normalize(mean=MEAN,\n","                          std=STD)\n","])\n","\n","train_dataset = BodyLandmarkDataset(data_root, is_Train=True, input_size=input_size, transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True)\n","\n","valid_dataset = BodyLandmarkDataset(data_root, is_Train=False, input_size=input_size, transform=transform)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"osvJGX4n4Miy"},"source":["# Misc\n","\n","class AverageMeter(object):\n","  \"\"\"Computes and stores the average and current value\"\"\"\n","  def __init__(self):\n","      self.reset()\n","\n","  def reset(self):\n","    self.val = 0\n","    self.avg = 0\n","    self.sum = 0\n","    self.count = 0\n","\n","  def update(self, val, n=1):\n","    self.val = val\n","    self.sum += val * n\n","    self.count += n\n","    self.avg = self.sum / self.count"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4edgVN4ovA0z"},"source":["----\n","#### **>>> 4.2.3 Training**\n","\n","```BodyLandmarkDataset```을 활용하여 Hourglass network를 학습할 시간입니다.\n","\n","- **TO DO Main (1)** : 본격적으로 학습하는 과정입니다. 주석에 적힌 내용을 따라 loss function인 ```criterion```과 ```optimizer```를 활용하여 빈 부분을 채워주세요.\n","\n","- **TO DO Main (2)** : 학습된 validation dataset에 대해 평가하는 과정입니다. Validation 과정에서는 <U>gradient 계산과 backpropagation이 필요 없다</U>는 것에 주목하여 빈 부분을 채워주세요."]},{"cell_type":"code","metadata":{"id":"yewH3ejYbsG5"},"source":["# Loss function and Optimizer\n","from torch.optim import Adam\n","\n","criterion = nn.MSELoss()\n","optimizer = Adam(model.parameters(), lr=lr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"I7WybHwZbtfY"},"source":["# Main\n","os.makedirs(log_dir, exist_ok=True)\n","\n","with open(os.path.join(log_dir, 'train_log.csv'), 'w') as log:\n","  for epoch in range(epochs):\n","    train_loss, valid_loss = AverageMeter(), AverageMeter()\n","\n","    # Training\n","    model.train()\n","    for iter, (img, hm_gt) in enumerate(train_loader):\n","      '''================================================================'''\n","      '''======================== TO DO Main (1) ========================'''\n","      # optimizer에 저장된 미분값을 0으로 초기화\n","      \n","\n","      # GPU 연산을 위해 이미지와 정답 tensor를 GPU로 보내기 (필요한 경우, 변수의 type도 수정해주세요)\n","      img, hm_gt = \n","\n","      # 모델에 이미지 forward\n","      pred_logit = \n","\n","      # loss 값 계산\n","      loss = 0\n","      for pred in pred_logit:\n","        loss += \n","\n","      # Backpropagation\n","      loss.backward()\n","      optimizer.step()\n","      '''======================== TO DO Main (1) ========================'''\n","      '''================================================================'''\n","\n","      # Log Update\n","      train_loss.update(loss.item(), len(img))\n","      print(\"\\rEpoch [%3d/%3d] | Iter [%3d/%3d] | Train Loss %.4f\" % (epoch+1, epochs, iter+1, len(train_loader), train_loss.avg), end='')\n","\n","    # Validation\n","    model.eval()\n","    for iter, (img, hm_gt) in enumerate(valid_loader):\n","      '''================================================================'''\n","      '''======================== TO DO Main (2) ========================'''\n","      # GPU 연산을 위해 이미지와 정답 tensor를 GPU로 보내기 (필요한 경우, 변수의 type도 수정해주세요)\n","      img, hm_gt = \n","\n","      # 모델에 이미지 forward (gradient 계산 X)\n","\n","        preds = \n","        \n","      # loss 값 계산\n","      loss = 0\n","      for pred in pred_logit:\n","        loss += \n","      '''======================== TO DO Main (2) ========================'''\n","      '''================================================================'''\n","\n","      # Log Update\n","      valid_loss.update(loss.item(), len(img))\n"," \n","    print(\"\\nEpoch [%3d/%3d] | Valid Loss %.4f\" % (epoch+1, epochs, valid_loss.avg))\n","    \n","    # Log Writing\n","    log.write('%d,%.4f,%.4f\\n'%(epoch, train_loss.avg, valid_loss.avg))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mBOCszlcvpoN"},"source":["#### **>>> 4.3.3 Visualization**\n","학습된 모델을 바탕으로 샘플 이미지에 대한 keypoint 예측 결과를 시각화하는 단계입니다.\n","\n","- **TO DO** : 아래의 시각화 코드를 활용하여 샘플 이미지에 대한 예측 결과를 시각화해주세요. (아래 예시 그림 참고) <img src='https://drive.google.com/uc?id=1zCiRG-vQ2lSantORSmQYbqH75rB9Rb5f'  width=\"400\">\n","\n","\n","- **TO DO Main** : 주석을 참고하여 inference를 위한 코드를 완성해주세요.\n","\n","- **TO DO Decoding** : 예측된 heatmap에서 좌표값 (x,y)를 얻어내는 코드를 완성해주세요.\n","<br>(1) ```pred_hm``` 변수는 (channels, height, width) shape을 가집니다.\n","<br>(2) ```hm``` 변수는 ```pred_hm```의 각 channel을 나타내며 (height, width) shape을 가집니다."]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"1eoFBtv_U_ar"},"source":["import matplotlib.pyplot as plt\n","\n","n_vis = 5\n","\n","# Visualize the result of validation dataset\n","for iter, (imgs, hm_gt) in enumerate(train_loader):\n","  '''============================================================'''\n","  '''======================== TO DO Main ========================'''\n","  # GPU 연산을 위해 이미지 tensor를 GPU로 보내기 (필요한 경우, 변수의 type도 수정해주세요)\n","  imgs = \n","  \n","  # 모델에 이미지 forward (gradient 계산 X)\n","\n","    preds = \n","  '''======================== TO DO Main ========================'''\n","  '''============================================================'''\n","\n","\n","  # for each sample in a batch\n","  imgs = imgs.cpu().numpy()\n","  for img, pred_hm in zip(imgs, preds):\n","    # Re-convert pre-processed input image to original format\n","    img = np.moveaxis(img, 0, -1)\n","    img = (img * STD) + MEAN\n","    img = (img*255).astype(np.uint8).copy()\n","\n","    for hm in pred_hm:\n","      '''======================================================='''\n","      '''==================== TO DO Decoding ==================='''\n","      y, x = \n","      '''==================== TO DO Decoding ==================='''\n","      '''======================================================='''\n","      cv2.circle(img, (x[0]*4, y[0]*4), 3, (255,0,0), -1)\n","    \n","    plt.imshow(img)\n","    plt.show()\n","  \n","\n","  if iter == (n_vis-1):\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CyNjYjW_li0P"},"source":["#### **Discussion**\n","\n","UNet과 Hourglass networks 과 같은 구조들은 각 레이어의 공간 해상도와 채널의 수가 바로 앞뒤 레이어 뿐만 아니라 훨씬 앞단 또는 뒷단과도 밀접한 의존성을 가지고 있고, 해상도를 줄였다가 올릴 때, 해상도의 rounding에 따른 차이가 쉽게 발생하는 구조입니다. 따라서, 어떤 경우에 해당 구조가 제대로 연결이 안될지, 어떤 입력 사이즈가 들어왔을 때 에러가 발생하는지 등에 대해서 고찰해보시기 바랍니다."]}]}