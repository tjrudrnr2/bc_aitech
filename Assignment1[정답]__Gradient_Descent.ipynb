{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPhRpnGbllOL"
   },
   "source": [
    "# Assignment 1: Gradient Descent\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "본 과제에서는 경사하강법(Gradient Descent)를 구현해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rPsh3Gm07LV"
   },
   "source": [
    "## 1. Gradient Descent (1)\n",
    "\n",
    "먼저 [SymPy library](https://www.sympy.org/en/index.html)를 사용하여 간단한 이차함수의 최솟값을 gradient descent 방법으로 찾는 문제입니다. - AI Math 3강 참고\n",
    "\n",
    "(SymPy: 수학 방정식의 기호(symbol)를 사용하게 해 주는 라이브러리)\n",
    "\n",
    " #### **def func**\n",
    "- `sym.poly` 함수는 함수식을 정의해줍니다.\n",
    "\n",
    "- `sym.subs` 함수는 변수를 다른변수로 치환하거나 값을 대입해줍니다.\n",
    "\n",
    "\n",
    "#### **func_gradient**\n",
    "- `sym.diff` 함수는 도함수를 구해줍니다.\n",
    "- `func` 함수를 사용하여 미분값과 함수를 return하는 코드를 짜야합니다.\n",
    "\n",
    "#### **gradient_descent**\n",
    "- `init_point`는 경사하강법의 시작점을 의미합니다.\n",
    "- `lr_rate`는 learning rate로 step의 크기를 정해줍니다.\n",
    "- `epsilon`은 gradient 크기의 lower bound입니다.\n",
    "- init_point부터 경사하강법을 시작해서, 최소점이 출력될 수 있도록 코드를 짜야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4bnWEgmKuJ1J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수: Poly(x**2 + 2*x + 3, x, domain='ZZ')\n",
      "연산횟수: 673\n",
      "최소점: (-0.999995020234038, 2.00000000002480)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sym\n",
    "from sympy.abc import x\n",
    "from sympy.plotting import plot\n",
    "\n",
    "def func(val):\n",
    "    fun = sym.poly(x**2 + 2*x + 3)\n",
    "    return fun.subs(x, val), fun\n",
    "\n",
    "def func_gradient(fun, val):\n",
    "    _, function = func(val)\n",
    "    diff = sym.diff(function, x)\n",
    "    return diff.subs(x, val), diff\n",
    "\n",
    "def gradient_descent(fun, init_point, lr_rate=1e-2, epsilon=1e-5):\n",
    "    cnt = 0\n",
    "    val = init_point\n",
    "    diff, _ = func_gradient(fun, val)\n",
    "    while np.abs(diff) > epsilon:\n",
    "        val = val - lr_rate*diff\n",
    "        diff, _ = func_gradient(fun, val)\n",
    "        cnt += 1\n",
    "    \n",
    "    print(\"함수: {}\\n연산횟수: {}\\n최소점: ({}, {})\".format(fun(val)[1], cnt, val, fun(val)[0]))\n",
    "\n",
    "gradient_descent(fun = func, init_point = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bROZY7uHCx3X"
   },
   "source": [
    "- 최종적으로 함수, 연산횟수, 최소점(-1,2)이 출력되면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YFdjdR5vC0bG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수: Poly(x**2 + 2*x + 3, x, domain='ZZ')\n",
      "연산횟수: 673\n",
      "최소점: (-0.999995020234038, 2.00000000002480)\n"
     ]
    }
   ],
   "source": [
    "gradient_descent(fun = func, init_point = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udMVpeMaXJhB"
   },
   "source": [
    "## 2. Gradient Descent (2)\n",
    "\n",
    "- 위의 예제에서 (-1,2)와 거의 동일한 최소점을 얻으셨나요? 그럼 이번에는 sympy library를 사용하지 않고 직접 Gradient Descent를 구현해봅시다!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1ygwhh4m2ex"
   },
   "source": [
    "$$ f'(x) = \\lim_{x \\rightarrow\n",
    " 0} \\frac{f(x+h)-f(x)}{h} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nYj3r-Pm1Ln"
   },
   "source": [
    "- 원래의 미분 공식은 위와 같이 h를 0의 극한으로 보내면 되지만, 컴퓨터 상에서는 불가능하기 때문에 h에 1e-9와 같이 아주 작은 수를 넣어줌으로써 유사한 변화율을 구합니다.\n",
    "\n",
    "#### **difference_quotient(f, x, h)**\n",
    "- h만큼 움직였을 때의 변화율을 계산해주는 코드입니다.\n",
    "- h는 1e-9와 같이 매우 작은 수가 들어갑니다.\n",
    "- f에는 아래에 정의된 func 함수가 들어가고, x에는 변화율을 계산할 point가 들어갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x4Lj4vl1KEDn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연산횟수: 672\n",
      "최소점: (-0.999994846459742, 2.00000000002656)\n"
     ]
    }
   ],
   "source": [
    "def func(val):\n",
    "    fun = sym.poly(x**2 + 2*x + 3)\n",
    "    return fun.subs(x, val)\n",
    "\n",
    "def difference_quotient(f, x, h=1e-9):\n",
    "    result = (f(x + h) - f(x)) / h\n",
    "    return result\n",
    "\n",
    "def gradient_descent(func, init_point, lr_rate=1e-2, epsilon=1e-5):\n",
    "    cnt = 0\n",
    "    val = init_point\n",
    "    diff = difference_quotient(func, val)\n",
    "    while np.abs(diff) > epsilon:\n",
    "        val = val - lr_rate*diff\n",
    "        diff = difference_quotient(func, val)\n",
    "        cnt += 1\n",
    "    \n",
    "    print(\"연산횟수: {}\\n최소점: ({}, {})\".format(cnt, val, func(val)))\n",
    "\n",
    "gradient_descent(func, init_point=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HzMqhLxC60r"
   },
   "source": [
    "- 최종적으로 연산횟수, 최소점(-1,2)이 출력되면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rg_K54iaC-rS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연산횟수: 672\n",
      "최소점: (-0.999994846459742, 2.00000000002656)\n"
     ]
    }
   ],
   "source": [
    "gradient_descent(func, init_point=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7C4-EzC4azr"
   },
   "source": [
    "## 3. Linear Regression\n",
    "- sympy library를 사용했을 때와 비슷한 결과값을 얻었나요?\n",
    "- 그럼 이제 본격적으로 Gradient Descent를 활용한 Linear Regression을 구현해 봅시다.\n",
    "\n",
    "### **3-1. Basic function**\n",
    "#### **Dataset 1** : train_x, train_y\n",
    "$$y = wx + b$$ $$y = 7x + 2$$\n",
    "- 위의 식을 알아내기 위해서 train_x, train_y의 data point를 가지고 Linear Regression을 진행합니다.\n",
    "\n",
    "#### **Gradient Descent**\n",
    "- error를 어떻게 계산하고, gradient를 통해 w와 b를 어떻게 조정해 나가는지에 대한 코드를 짜주시면 됩니다.\n",
    "    - error는 L2 norm으로 사용하고, np.sum 함수를 활용하시면 됩니다.\n",
    "- 결과값이 (7,2)와 유사하게 출력이 되면 성공입니다 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y4yOk4jR4aog"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w : 7.005345319843033 / b : 1.2921075180381343 / error : 0.5109907472787187\n"
     ]
    }
   ],
   "source": [
    "train_x = (np.random.rand(1000) - 0.5) * 10\n",
    "train_y = np.zeros_like(train_x)\n",
    "\n",
    "def func(val):\n",
    "    fun = sym.poly(7*x + 2)\n",
    "    return fun.subs(x, val)\n",
    "\n",
    "for i in range(1000):\n",
    "    train_y[i] = func(train_x[i])\n",
    "\n",
    "# initialize\n",
    "w, b = 0.0, 0.0\n",
    "\n",
    "lr_rate = 1e-2\n",
    "n_data = len(train_x)\n",
    "errors = []\n",
    "\n",
    "for i in range(100):\n",
    "    _y = train_x * w + b\n",
    "    error = np.sum((_y - train_y) ** 2) / n_data\n",
    "\n",
    "    gradient_w = np.sum((_y - train_y) * train_x) / n_data\n",
    "    gradient_b = np.sum((_y - train_y)) / n_data\n",
    "\n",
    "    w -= lr_rate * gradient_w\n",
    "    b -= lr_rate * gradient_b\n",
    "\n",
    "    errors.append(error)\n",
    "\n",
    "print(\"w : {} / b : {} / error : {}\".format(w, b, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqXgO77MDMvN"
   },
   "source": [
    "* 이제 plot 함수를 이용해서 full-batch gradient descent를 사용한 경우, error가 어떻게 줄어드는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yPfF6tHbDQSR"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot(errors):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.ylabel('error')\n",
    "    plt.xlabel('time step')\n",
    "    plt.plot(errors)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WmNczAWrDRm2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOU3Rq3TDVHp"
   },
   "source": [
    "### **3.2. More complicated function**\n",
    "#### **Dataset 2** : train_x, train_y\n",
    "- 이번에는 좀 더 복잡한 선형식에 대한 Regression을 진행해봅시다 !\n",
    "$$ y = w_0x_0 + w_1x_1 + w_2x_2 + b $$\n",
    "$$ y = x_0 + 3x_1 + 5x_2 + 7$$\n",
    "\n",
    "- 각 element의 계수를 beta_gd로 설정 : random initialize ( 목표 정답은 [1, 3, 5, 7] )\n",
    "- 이번에는 np.transpose 함수를 활용하여 gradient를 계산해봅시다 ( AI Math 4강 참고 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbCGTSZt1LRC"
   },
   "outputs": [],
   "source": [
    "train_x = np.array([[1,1,1], [1,1,2], [1,2,2], [2,2,3], [2,3,3], [1,2,3]])\n",
    "train_y = np.dot(train_x, np.array([1,3,5])) + 7\n",
    "\n",
    "# random initialize\n",
    "beta_gd = [9.4, 10.6, -3.7, -1.2]\n",
    "# for constant element\n",
    "expand_x = np.array([np.append(x, [1]) for x in train_x])\n",
    "\n",
    "for t in range(5000):\n",
    "    pred_y = expand_x @ beta_gd\n",
    "    error = train_y - pred_y\n",
    "    grad = -np.transpose(expand_x) @ error\n",
    "\n",
    "    beta_gd = beta_gd - 0.01 * grad\n",
    "\n",
    "print(\"After gradient descent, beta_gd : {}\".format(beta_gd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHRiic4_6LlB"
   },
   "source": [
    "## 4. Stochastic Gradient Descent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH4lCXrGDezY"
   },
   "source": [
    "- 3-1의 문제와 동일한 문제에 대해서 Stochastic Gradient Descent를 사용해봅시다.\n",
    "\n",
    "- Code와 dataset 모두 동일하게 사용하되, 기존의 Dataset으로부터 mini-batch를 구성해서 Gradient Descent를 진행해주시면 됩니다.\n",
    "    - mini-batch의 경우, **np.random.choice** 함수를 활용하셔서 1,000개의 dataset 중 10개를 뽑아서 만들어주시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nn8133mq6obv"
   },
   "outputs": [],
   "source": [
    "train_x = (np.random.rand(1000) - 0.5) * 10\n",
    "train_y = np.zeros_like(train_x)\n",
    "\n",
    "def func(val):\n",
    "    fun = sym.poly(7*x + 2)\n",
    "    return fun.subs(x, val)\n",
    "\n",
    "for i in range(1000):\n",
    "    train_y[i] = func(train_x[i])\n",
    "\n",
    "# initialize\n",
    "w, b = 0.0, 0.0\n",
    "\n",
    "lr_rate = 1e-2\n",
    "n_data = 10\n",
    "errors = []\n",
    "\n",
    "for i in range(100):\n",
    "    idx = np.random.choice(1000, 10, replace=False)\n",
    "    mini_x = train_x[idx]\n",
    "    mini_y = train_y[idx]\n",
    "\n",
    "    _y = mini_x * w + b\n",
    "    error = np.sum((_y - mini_y) ** 2) / n_data\n",
    "\n",
    "    gradient_w = np.sum((_y - mini_y) * mini_x) / n_data\n",
    "    gradient_b = np.sum((_y - mini_y)) / n_data\n",
    "\n",
    "    w -= lr_rate * gradient_w\n",
    "    b -= lr_rate * gradient_b\n",
    "\n",
    "    # Error graph 출력하기 위한 부분\n",
    "    errors.append(error)\n",
    "\n",
    "print(\"w : {} / b : {} / error : {}\".format(w, b, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZE2CsZWDj7W"
   },
   "source": [
    "- plot 함수를 이용해서 mini-batch를 사용한 stochastic gradient descent의 경우, error가 어떻게 줄어드는지 확인해봅시다.\n",
    "- 3.1의 full-batch gradient descent를 사용한 경우와 plot을 통해 비교를 해보면 차이를 좀 더 명확히 확인할 수 있습니다.\n",
    "    - full-batch의 경우, 매 epoch마다 전체 dataset을 모두 사용하여 GD를 하기 때문에 그래프가 매끄럽지만, SGD에 비하여 초기 수렴속도가 느린 편입니다.\n",
    "    - mini-batch의 경우, 매 epoch마다 mini-batch를 sampling해서 GD를 하기 때문에 그래프가 매끄럽지 않지만, 그만큼 초기에 빠르게 minimum으로 수렴하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCpqNbBsDidu"
   },
   "outputs": [],
   "source": [
    "plot(errors)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment1[정답]_ Gradient Descent.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
